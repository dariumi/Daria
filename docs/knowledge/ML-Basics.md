# Основы ML

## Градиентный спуск
Градиентный спуск — это метод оптимизации, который шаг за шагом уменьшает ошибку модели.
На каждом шаге параметры смещаются в сторону, противоположную градиенту функции потерь.
Размер шага задаётся learning rate: слишком большой шаг может «перепрыгивать» минимум, слишком маленький — обучаться очень медленно.

## Переобучение
Переобучение возникает, когда модель запоминает обучающие данные и хуже работает на новых примерах.
Обычно помогает регуляризация, больше данных, аугментации или early stopping.

## Валидация
Для оценки качества разделяют данные на train/validation/test, чтобы контролировать обобщающую способность.
